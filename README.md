# Cyberbuddhism

Life doesn't have a global reward function. Therefore, it's mathematically impossible to live an Optimal Life.

We believe it's a feature, not a bug. We can _choose_ our reward function.

To make things interesting, we can choose a very specific reward function:

`Reward = Sum of time intervals spent following a locally-optimal policy`

A policy is a function from state to action. A locally-optimal policy is a policy that maximizes a local reward function. Paradoxically, our local reward function may become quite unrewarding when optimized for.

However, you can define a locally-optimal policy & follow it for a limited time. After timeout, you can define a new locally-optimal policy. This is quite similar to how we live our lives - we focus on a specific reward function for some time, then switch to another reward function.

The difference is how we feel about it. Instead of feeling bad about switching all the time, we can feel good about... switching all the time!

**A feature, not a bug.**

But there's a catch.

It works only if you truly believe that following a sequence of locally-optimal policies is the most globally-optimal policy. There's no way to prove it, only faith remains.

Either way, it's your choice.

... and if your choice is "Yes" - then you're welcome to join the community of people who made the same choice. We're helping each other with policy optimization at war & in love.

P.S. If your choice is "unsat" instead of "Yes", you might be interested in this puzzle...
