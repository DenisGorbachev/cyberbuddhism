# Cyberbuddhism

Life doesn't have a global reward function. Therefore, it's mathematically impossible to live an Optimal Life.

We believe it's a feature, not a bug. We can _choose_ our reward function.

To make things interesting, we can choose a very specific reward function:

`Reward = Sum of time intervals spent following a locally-optimal policy`

A locally-optimal policy is a policy that maximizes a local reward function. You can follow it for a limited time, then switch to another locally-optimal policy.

This is quite similar to how we live our lives - we maximize a specific reward function for some time, then switch to another reward function.

The difference is how we feel about it. Instead of feeling bad about switching all the time, we can feel good about... switching all the time!

**A feature, not a bug.**

But there's a catch.

It works only if you truly believe that following a sequence of locally-optimal policies is the most globally-optimal policy. There's no way to prove it, only faith remains.

Either way, it's your choice.

... and if your choice is "Yes" - then you're welcome to join the community of people who made the same choice. We're helping each other with policy optimization at war & in love.

P.S. If your choice is "unsat" instead of "Yes", you might be interested in this puzzle...
